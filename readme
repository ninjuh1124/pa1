(c) 2018 Michael Verastegui

The calc program takes in a +/- operator, two 64-bit numbers in the assignment-specified format, and an output base. The main source file does all the input validation and error checking, though it implements a written function from convertToDecimal (which in retrospect should be named convertToTwosComp, but whatever). If I had planned things out better, I probably would have put an int return on the convertToDecimal() function for success or failure, and thereby parsing each number string only once, cutting runtime in half, but it runs in O(1) time for worst case regardless, since the maximum string length that will be accepted is 65 characters. Space complexity is O(1) since all arguments are passed by memory address.

The format program takes in a 32-bit number in string. It's parsed through two's complement and unioned with a float. If the second argument is "int", the two's complement value is converted into a decimal value ASCII string using more or less the same algorithm as in the calc program. If the second argument is "float", for whatever reason, a 1 followed by 31 0s is passed to the floatToASCII function, and I have literally no idea why. 
